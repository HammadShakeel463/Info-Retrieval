Qno1: What are the two data structures choices while implementing dictionaries? which one you preferred and why? 
The two common data structure choices for implementing dictionaries are hash tables and binary search trees.
Hash tables are preferred when the keys have a uniform distribution, and there are no collisions (i.e., different keys that map to the same index). They provide constant time lookup and insertion, which makes them ideal for applications that require fast access to key-value pairs, such as caches, symbol tables, and database indexing.
On the other hand, binary search trees are preferred when the keys have a non-uniform distribution or need to be sorted in a specific order. They provide O(log n) lookup, insertion, and deletion operations on average, which makes them ideal for applications that require ordered traversal or range queries, such as database queries and data analytics.

Qno2: What do we mean by "Wild Card Queries"? what are their different types? give examples
Wild card queries are a type of query in information retrieval systems that allows users to search for words or phrases with missing or unknown letters by using a special character, often an asterisk (*), to represent the missing letters. The use of wild card queries allows for more flexible and powerful search capabilities.

There are two main types of wild card queries:

Leading Wild Card Queries - In this type of query, the wildcard is placed at the beginning of the search term. For example, searching for " *apple" would return all words that end with "apple", such as "pineapple", "snapple", "honeycrispapple", etc.

Trailing Wild Card Queries - In this type of query, the wildcard is placed at the end of the search term. For example, searching for "app*" would return all words that start with "app", such as "apple", "application", "applesauce", etc.
examples:
Searching for "wom*n" would match "woman" and "women"
Searching for "colo*r" would match "color" and "colour"

Qno3:What is a Permuterm Index? How it can support the general Wild Card Queries?
A permuterm index is a data structure used in information retrieval to facilitate substring and wildcard searches. It works by generating all possible permutations of a given word and adding them to the index along with the original word. Each permutation of a word is generated by appending a special character (e.g., $) to the end of the word and rotating the character to the beginning until the original word is reached. 
To support wild card queries, the permuterm index can be augmented with a leading wildcard character (e.g., *) to allow for partial matches at the beginning of the word. For example, a search for "ample" would be transformed into the permuterm "ample$" and would match all words in the index that end with "ample". Similarly, a trailing wildcard character can be used to allow for partial matches at the end of the word.

One advantage of the permuterm index over other wildcard search techniques is that it requires only a single index lookup per query term, regardless of the number of wildcards used in the query. This makes it more efficient for handling queries with multiple wildcards.

One disadvantage of the permuterm index is that its dictionary becomes quite large, including as it does all rotations of each term.

Qno4: What is a k-gram index? How it can support the general Wild Card Queries? 

A k-gram index is a data structure used in information retrieval to facilitate substring searches and approximate string matching. It works by dividing a string into all possible consecutive substrings of length k (k-grams) and adding them to the index along with their positions in the string. For example, the k-grams of the word "example" with k=3 would be: "exa", "xam", "amp", "mpl", "ple". The k-gram index would store these k-grams along with the position of the word "example" in the original string.

To support wildcard queries, the k-gram index can be used to generate a set of candidate words that match the query pattern. The query is transformed into a sequence of k-grams, which are then matched against the k-grams in the index. For example, a query for "amp" would be transformed into the k-grams "amp" and "mp*". The k-gram index would then return all words that contain both of these k-grams, such as "example", "champagne", "lampshade", etc.
One advantage of the k-gram index over other wildcard search techniques is that it can handle queries with both leading and trailing wildcards. For example, a query for "amp" would match "champagne", but a query for "*amp" would match "lamp", "damp", etc.

Qno5: When Soundex based search is required? give example?
Soundex based search is a phonetic algorithm used to match words that sound similar but are spelled differently. It is commonly used in information retrieval to improve the recall of a search by including words that may be misspelled or have alternative spellings. Soundex maps each word to a code based on its pronunciation and then searches for words that have the same code.

Soundex based search is particularly useful in situations where the user may not know the correct spelling of a word or may be using a different dialect or language than the one used in the indexed documents. For example, a user searching for the name "Smith" may not know that it is spelled "Smyth" in the document they are searching, or they may be searching in a different language where the name is spelled differently.

Qno6: Write down the entries in the permuterm index dictionary that are generated by the terms { "mama", "chacha", "Tullo"}
For "mama":
"mama$" -> "mama$"
"ama$m" -> "mama$"
"ma$am" -> "mama$"
"a$mam" -> "mama$"
For "chacha":
"chacha$" -> "chacha$"
"hacha$c" -> "chacha$"
"acha$ch" -> "chacha$"
"cha$cha" -> "chacha$"
"ha$chac" -> "chacha$"
"a$chach" -> "chacha$"
For "Tullo":
"Tullo$" -> "Tullo$"
"ullo$T" -> "Tullo$"
"llo$Tu" -> "Tullo$"
"lo$Tul" -> "Tullo$"
"o$Tull" -> "Tullo$

Qno7: If you wanted to search for s*ng in a permuterm wildcard index, what key(s) would one do the lookup on? 

Add a special character (such as "$") to the end of the search term to indicate the end of the string: "s*ng$"

Rotate the resulting string to generate all possible suffixes:

"s*ng$"
"*ng$s"
"ng$s*"
"g$s*n"
"$s*ng"
"s*ng$"
"*ng$s"
"ng$s*"
For each rotated suffix, perform a lookup in the permuterm index to find all terms that end with that suffix.
Therefore, to search for "sng" in a permuterm index, we would perform lookups on the following keys: "sng$", "ng$s", "ng$s", "g$sn", "$sng", "s*ng$", "ng$s", and "ng$s". This would return all terms that match the pattern "s" followed by any number of characters and ending with "ng"

Qno8: Give an example of a sentence that falsely matches the wildcard query mon*h if the search were to simply use a conjunction of bigrams. 
If we were to simply use a conjunction of bigrams to match the wildcard query "mon*h", we might falsely match a sentence like "The monkey is on the branch" because it contains the bigrams "mon" and "on". This false match occurs because the bigram approach only considers adjacent pairs of words and does not account for the presence of other words in between.
If we perform a conjunction of bigrams search for "monh", we would match the bigrams "mon" and "on" in the first and fourth bigrams, respectively. However, this would incorrectly suggest a match for the term "monh" because there is no word in between "mon" and "on".

Qno9: What is so special about context sensitive spelling correction? 

Context-sensitive spelling correction is a type of spelling correction that takes into account the context of the word being corrected, rather than simply suggesting corrections based on the spelling of individual words.

Context-sensitive spelling correction is special because it allows for more accurate and meaningful corrections to be suggested, especially in cases where multiple corrections may be valid based solely on the spelling of the word. For example, the word "lead" can be a verb meaning to guide, or a noun meaning a heavy metal. Depending on the context in which the word is used, a context-sensitive spelling correction algorithm can suggest the appropriate correction.

Context-sensitive spelling correction can be implemented using techniques such as N-gram language modeling, where the likelihood of a given word being used in a particular context is estimated based on the frequency of occurrence of sequences of words in a large corpus of text. This allows the correction algorithm to suggest corrections that are more likely to be the correct spelling based on the context in which the word is being used.

Qno10: Why do you think soundex approach is not good for IR? 
Limited matching: it does not take into account variations in spelling or meaning. 
Limited precision:oundex is a relatively simple algorithm that reduces words to a small set of phonetic codes, which can result in a loss of information and precision. For example, two words that have the same Soundex code may not be similar in meaning or context.
Limited flexibility:
Not suitable for languages other than English: 

